<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Penalized Factor Analysis: grid search • penfa</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/readable/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Penalized Factor Analysis: grid search">
<meta property="og:description" content="penfa">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">penfa</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/automatic-tuning-selection.html">Penalized Factor Analysis</a>
    </li>
    <li>
      <a href="../articles/grid-search-tuning-selection.html">Penalized Factor Analysis: grid search</a>
    </li>
    <li>
      <a href="../articles/multiple-group-analysis.html">Penalized Multiple-Group Factor Analysis</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="grid-search-tuning-selection_files/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="grid-search-tuning-selection_files/htmlwidgets-1.5.3/htmlwidgets.js"></script><script src="grid-search-tuning-selection_files/plotly-binding-4.9.4.1/plotly.js"></script><script src="grid-search-tuning-selection_files/typedarray-0.1/typedarray.min.js"></script><script src="grid-search-tuning-selection_files/jquery-3.5.1/jquery.min.js"></script><link href="grid-search-tuning-selection_files/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet">
<script src="grid-search-tuning-selection_files/crosstalk-1.1.1/js/crosstalk.min.js"></script><link href="grid-search-tuning-selection_files/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="grid-search-tuning-selection_files/plotly-main-1.57.1/plotly-latest.min.js"></script><link href="grid-search-tuning-selection_files/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="grid-search-tuning-selection_files/datatables-binding-0.18/datatables.js"></script><link href="grid-search-tuning-selection_files/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="grid-search-tuning-selection_files/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="grid-search-tuning-selection_files/dt-core-1.10.20/js/jquery.dataTables.min.js"></script><script src="grid-search-tuning-selection_files/jszip-1.10.20/jszip.min.js"></script><script src="grid-search-tuning-selection_files/pdfmake-1.10.20/pdfmake.js"></script><script src="grid-search-tuning-selection_files/pdfmake-1.10.20/vfs_fonts.js"></script><link href="grid-search-tuning-selection_files/dt-ext-buttons-1.10.20/css/buttons.dataTables.min.css" rel="stylesheet">
<script src="grid-search-tuning-selection_files/dt-ext-buttons-1.10.20/js/dataTables.buttons.min.js"></script><script src="grid-search-tuning-selection_files/dt-ext-buttons-1.10.20/js/buttons.flash.min.js"></script><script src="grid-search-tuning-selection_files/dt-ext-buttons-1.10.20/js/buttons.html5.min.js"></script><script src="grid-search-tuning-selection_files/dt-ext-buttons-1.10.20/js/buttons.colVis.min.js"></script><script src="grid-search-tuning-selection_files/dt-ext-buttons-1.10.20/js/buttons.print.min.js"></script><link href="grid-search-tuning-selection_files/dt-ext-scroller-1.10.20/css/scroller.dataTables.min.css" rel="stylesheet">
<script src="grid-search-tuning-selection_files/dt-ext-scroller-1.10.20/js/dataTables.scroller.min.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Penalized Factor Analysis: grid search</h1>
            
      
      
      <div class="hidden name"><code>grid-search-tuning-selection.Rmd</code></div>

    </div>

    
    
<style type="text/css">
pre {
  max-height: 600px;
  overflow-y: auto;
}

pre[class] {
  max-height: 600px;
}
</style>
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p><strong>Aim</strong>. This vignette shows how to fit a penalized factor analysis model with the scad and mcp penalties using the routines in the <code>penfa</code> package. The employed penalty is aimed at encouraging sparsity in the factor loading matrix. Since the scad and mcp penalties cannot be used with the automatic tuning procedure (see Geminiani et al., 2021 for details), the optimal tuning parameter will be found through grid searches.</p>
<p><strong>Data</strong>. For illustration purposes, we use the cross-cultural data set <code>ccdata</code> containing the standardized ratings to 12 items concerning organizational citizenship behavior. Employees from different countries were asked to rate their attitudes towards helping other employees and giving suggestions for improved work conditions. The items are thought to measure two latent factors: <strong>help</strong>, defined by the first seven items (<code>h1</code> to <code>h7</code>), and <strong>voice</strong>, represented by the last five items (<code>v1</code> to <code>v5</code>). See <code><a href="../reference/ccdata.html">?ccdata</a></code> for details.</p>
<p>This data set is a standardized version of the one in the <a href="https://github.com/Jo-Karl/ccpsyc/"><code>ccpsyc</code></a> package, and only considers employees from Lebanon and Taiwan (i.e., <code>"LEB"</code>, <code>"TAIW"</code>). This vignette is meant as a demo of the capabilities of <code>penfa</code>; please refer to Fischer et al. (2019) and Fischer and Karl (2019) for a description and analysis of these data.</p>
<p>Let us load and inspect <code>ccdata</code>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">penfa</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">ccdata</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">ccdata</span><span class="op">)</span>
<span class="co">##    country                h1                 h2                h3                 h4         </span>
<span class="co">##  Length:767         Min.   :-2.62004   Min.   :-2.9034   Min.   :-2.63082   Min.   :-3.0441  </span>
<span class="co">##  Class :character   1st Qu.:-0.69516   1st Qu.:-0.2163   1st Qu.:-0.70356   1st Qu.:-0.2720  </span>
<span class="co">##  Mode  :character   Median :-0.05354   Median : 0.4554   Median :-0.06114   Median : 0.4211  </span>
<span class="co">##                     Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.0000  </span>
<span class="co">##                     3rd Qu.: 0.58809   3rd Qu.: 0.4554   3rd Qu.: 0.58128   3rd Qu.: 0.4211  </span>
<span class="co">##                     Max.   : 1.22971   Max.   : 1.1272   Max.   : 1.22370   Max.   : 1.1141  </span>
<span class="co">##        h5                h6                h7                v1                  v2           </span>
<span class="co">##  Min.   :-2.9105   Min.   :-2.9541   Min.   :-2.8364   Min.   :-2.627694   Min.   :-2.674430  </span>
<span class="co">##  1st Qu.:-0.8662   1st Qu.:-0.9092   1st Qu.:-0.7860   1st Qu.:-0.660770   1st Qu.:-0.671219  </span>
<span class="co">##  Median : 0.4966   Median : 0.4541   Median :-0.1025   Median :-0.005129   Median :-0.003482  </span>
<span class="co">##  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.000000   Mean   : 0.000000  </span>
<span class="co">##  3rd Qu.: 0.4966   3rd Qu.: 0.4541   3rd Qu.: 0.5810   3rd Qu.: 0.650512   3rd Qu.: 0.664255  </span>
<span class="co">##  Max.   : 1.1781   Max.   : 1.1358   Max.   : 1.2645   Max.   : 1.306154   Max.   : 1.331992  </span>
<span class="co">##        v3                 v4                 v5          </span>
<span class="co">##  Min.   :-2.65214   Min.   :-2.65722   Min.   :-2.51971  </span>
<span class="co">##  1st Qu.:-0.68800   1st Qu.:-0.68041   1st Qu.:-0.61127  </span>
<span class="co">##  Median :-0.03329   Median :-0.02148   Median : 0.02488  </span>
<span class="co">##  Mean   : 0.00000   Mean   : 0.00000   Mean   : 0.00000  </span>
<span class="co">##  3rd Qu.: 0.62142   3rd Qu.: 0.63746   3rd Qu.: 0.66103  </span>
<span class="co">##  Max.   : 1.27613   Max.   : 1.29639   Max.   : 1.29718</span></code></pre></div>
</div>
<div id="model-specification" class="section level2">
<h2 class="hasAnchor">
<a href="#model-specification" class="anchor"></a>Model specification</h2>
<p>Before fitting the model, we need to write a model syntax describing the relationships between the items and the latent factors. To facilitate its formulation, the rules for the syntax specification broadly follow the ones required by <a href="https://cran.r-project.org/web/packages/lavaan/">lavaan</a>. The syntax must be enclosed in single quotes <code>' '</code>.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">syntax</span> <span class="op">=</span> <span class="st">'help  =~   h1 + h2 + h3 + h4 + h5 + h6 + h7 + 0*v1 + v2 + v3 + v4 + v5
          voice =~ 0*h1 + h2 + h3 + h4 + h5 + h6 + h7 +   v1 + v2 + v3 + v4 + v5'</span></code></pre></div>
<p>The factors <code>help</code> and <code>voice</code> appear on the left-hand side, whereas the observed variables on the left-hand side. Following the rationale in Geminiani et al. (2021), we only specify the minimum number of identification constraints. We are setting the scales of the factors by fixing their factor variances to 1. This can be done in one of two ways: 1) by adding <code>'help ~~ 1*help'</code> and <code>'voice ~~ 1*voice'</code> to the syntax above; or 2) by setting the argument <code>std.lv = TRUE</code> in the fitting function (see below). To avoid rotational freedom, we fix one loading per factor to zero. Parameters can be easily fixed to user-defined values through the pre-multiplication mechanism. By default, unique variances are automatically added to the model, and the factors are allowed to correlate. These specifications can be modified by altering the syntax (see <code><a href="../reference/penfa.html">?penfa</a></code> for details on how to write the model syntax).</p>
</div>
<div id="model-fitting" class="section level2">
<h2 class="hasAnchor">
<a href="#model-fitting" class="anchor"></a>Model fitting</h2>
<p>The core of the package is given by the <code>penfa</code> function, a short form for <em>PENalized Factor Analysis</em>, that implements the framework discussed in Geminiani et al. (2021). If users decide for either the <code>scad</code> or <code>mcp</code> penalties, they need to use <code>strategy = "fixed"</code> since the automatic procedure is not feasible.</p>
<div id="scad" class="section level3">
<h3 class="hasAnchor">
<a href="#scad" class="anchor"></a>Scad</h3>
<p>We start off with the scad. In the function call, we now specify <code>pen.shrink = "scad"</code>, and we provide through the <code>eta</code> argument the fixed value of the tuning parameter to be employed during optimization (here, for instance, 0.05). The name given to the starting value (here, the factor loading matrix <code>"lambda"</code>) reflects the parameter matrix to be penalized. All of its elements are penalized, which means here that the penalization is applied to all factor loadings (except the ones fixed for identification). The scad penalty relies on an additional shape parameter, which is set by default to 3.7 (Fan and Li 2001). This value can be conveniently modified through the <code>a.scad</code> argument. See <code><a href="../reference/penfaOptions.html">?penfaOptions</a></code> for additional details on the possible options.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">scad.fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/penfa.html">penfa</a></span><span class="op">(</span><span class="co">## factor model</span>
                  model  <span class="op">=</span> <span class="va">syntax</span>,
                  data   <span class="op">=</span> <span class="va">ccdata</span>,
                  std.lv <span class="op">=</span> <span class="cn">TRUE</span>,
                  <span class="co">## penalization</span>
                  pen.shrink <span class="op">=</span> <span class="st">"scad"</span>,
                  eta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>shrink <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lambda"</span> <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span>, diff <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"none"</span> <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span>,
                  <span class="co">## fixed tuning</span>
                  strategy <span class="op">=</span> <span class="st">"fixed"</span><span class="op">)</span>
<span class="co">## </span>
<span class="co">## Largest absolute gradient value: 27.97150845</span>
<span class="co">## Fisher information matrix is positive definite</span>
<span class="co">## Eigenvalue range: [164.74, 382028.4]</span>
<span class="co">## Trust region iterations: 24 </span>
<span class="co">## Factor solution: admissible </span>
<span class="co">## Computing VCOV ... done.</span>
<span class="co">## Effective degrees of freedom: 27.94395</span></code></pre></div>
<div id="grid-search" class="section level4">
<h4 class="hasAnchor">
<a href="#grid-search" class="anchor"></a>Grid search</h4>
<p>In order to find the optimal value of the tuning parameter, a grid search needs to be conducted, and the optimal model is the one with the lowest GBIC (Generalized Bayesian Information Criterion). For demo purposes, we use a grid of 51 values evenly spaced between 0 and 0.15. However, for accurate analyses, please consider finer grids (of at least 200 elements) with an upper bound reasonable for the data at hand.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Grid of values for tuning parameter</span>
<span class="va">eta.grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.15</span>, length.out <span class="op">=</span> <span class="fl">51</span><span class="op">)</span>

<span class="co"># Return GBIC from a converged and admissible penfa model with fixed tuning</span>
<span class="va">penfa.fixedTun</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">eta</span>, <span class="va">penalty</span>, <span class="va">...</span><span class="op">)</span><span class="op">{</span>
  
  <span class="va">fitted</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/penfa.html">penfa</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">syntax</span>, data <span class="op">=</span> <span class="va">ccdata</span>, 
                  std.lv <span class="op">=</span> <span class="cn">TRUE</span>, pen.shrink <span class="op">=</span> <span class="va">penalty</span>, 
                  eta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>shrink <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lambda"</span> <span class="op">=</span> <span class="va">eta</span><span class="op">)</span>, diff <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"none"</span> <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span>,
                  strategy <span class="op">=</span> <span class="st">"fixed"</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span>, <span class="va">...</span><span class="op">)</span>
  
  <span class="kw">if</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/all.html">all</a></span><span class="op">(</span><span class="va">fitted</span><span class="op">@</span><span class="va">Vcov</span><span class="op">$</span><span class="va">solution</span><span class="op">)</span> <span class="op">&amp;</span> <span class="va">fitted</span><span class="op">@</span><span class="va">Vcov</span><span class="op">$</span><span class="va">admissibility</span><span class="op">)</span>
    <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html">BIC</a></span><span class="op">(</span><span class="va">fitted</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span>

<span class="co"># additional penfaOptions can be passed</span>
<span class="va">GBIC.scad</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">eta.grid</span>, <span class="va">penfa.fixedTun</span>, penalty <span class="op">=</span> <span class="st">"scad"</span><span class="op">)</span> </code></pre></div>
<p>We can plot <code>GBIC</code> values across the tuning values.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">optimtun.scad</span> <span class="op">&lt;-</span> <span class="va">eta.grid</span><span class="op">[[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">GBIC.scad</span><span class="op">)</span><span class="op">]</span><span class="op">]</span>
  
<span class="va">p</span> <span class="op">&lt;-</span> <span class="fu">plotly</span><span class="fu">::</span><span class="fu"><a href="https://docs.ropensci.org/plotly/reference/plot_ly.html">plot_ly</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">eta.grid</span>, y <span class="op">=</span> <span class="va">GBIC.scad</span>, type <span class="op">=</span> <span class="st">'scatter'</span>, mode <span class="op">=</span> <span class="st">'lines'</span><span class="op">)</span>
<span class="fu">plotly</span><span class="fu">::</span><span class="fu"><a href="https://docs.ropensci.org/plotly/reference/layout.html">layout</a></span><span class="op">(</span><span class="va">p</span>, xaxis <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>showline <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,
               title <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>text <span class="op">=</span> <span class="st">"GBIC values across tuning parameters"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div id="htmlwidget-f35ad437f08fac6f6dc8" style="width:576px;height:384px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-f35ad437f08fac6f6dc8">{"x":{"visdat":{"93a29d6dda4":["function () ","plotlyVisDat"]},"cur_data":"93a29d6dda4","attrs":{"93a29d6dda4":{"x":[0,0.003,0.006,0.009,0.012,0.015,0.018,0.021,0.024,0.027,0.03,0.033,0.036,0.039,0.042,0.045,0.048,0.051,0.054,0.057,0.06,0.063,0.066,0.069,0.072,0.075,0.078,0.081,0.084,0.087,0.09,0.093,0.096,0.099,0.102,0.105,0.108,0.111,0.114,0.117,0.12,0.123,0.126,0.129,0.132,0.135,0.138,0.141,0.144,0.147,0.15],"y":[17396.1792565921,17389.6012374136,17379.9066385034,17376.4933434123,17366.7044811975,17362.9101329404,17359.7359863997,17357.9478208619,17355.6179026994,17354.7787217261,17354.2846261666,17353.9725309276,17353.7606357444,17353.5986274967,17353.7553938161,17353.3260626243,17352.8052248731,17352.3055358208,17351.8159561802,17351.0772415463,17350.3711186799,17349.6894638604,17349.1586542158,17348.7143362039,17349.0346381527,17349.1580878401,17349.3188132048,17349.6555762298,17349.9538948193,17350.2351363356,17350.5012800874,17350.6679163188,17350.3123240374,17350.0606491985,17349.9086087174,17347.4089628504,17347.2129429699,17347.1602144065,17347.1311525381,17347.2659201089,17347.886544954,17348.7132813606,17349.9509746262,17349.041919505,17349.2633171875,17349.51305498,17349.7813486608,17350.5395213189,17351.0540993595,17350.9051164779,17350.8556607212],"mode":"lines","alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"xaxis":{"domain":[0,1],"automargin":true,"showline":true,"title":[]},"title":{"text":"GBIC values across tuning parameters"},"yaxis":{"domain":[0,1],"automargin":true,"title":[]},"hovermode":"closest","showlegend":false},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[0,0.003,0.006,0.009,0.012,0.015,0.018,0.021,0.024,0.027,0.03,0.033,0.036,0.039,0.042,0.045,0.048,0.051,0.054,0.057,0.06,0.063,0.066,0.069,0.072,0.075,0.078,0.081,0.084,0.087,0.09,0.093,0.096,0.099,0.102,0.105,0.108,0.111,0.114,0.117,0.12,0.123,0.126,0.129,0.132,0.135,0.138,0.141,0.144,0.147,0.15],"y":[17396.1792565921,17389.6012374136,17379.9066385034,17376.4933434123,17366.7044811975,17362.9101329404,17359.7359863997,17357.9478208619,17355.6179026994,17354.7787217261,17354.2846261666,17353.9725309276,17353.7606357444,17353.5986274967,17353.7553938161,17353.3260626243,17352.8052248731,17352.3055358208,17351.8159561802,17351.0772415463,17350.3711186799,17349.6894638604,17349.1586542158,17348.7143362039,17349.0346381527,17349.1580878401,17349.3188132048,17349.6555762298,17349.9538948193,17350.2351363356,17350.5012800874,17350.6679163188,17350.3123240374,17350.0606491985,17349.9086087174,17347.4089628504,17347.2129429699,17347.1602144065,17347.1311525381,17347.2659201089,17347.886544954,17348.7132813606,17349.9509746262,17349.041919505,17349.2633171875,17349.51305498,17349.7813486608,17350.5395213189,17351.0540993595,17350.9051164779,17350.8556607212],"mode":"lines","type":"scatter","marker":{"color":"rgba(31,119,180,1)","line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"xaxis":"x","yaxis":"y","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script><p>We can ultimately fit the model with the optimal tuning parameter (here, 0.114), that is, the one generating the penalized model with the lowest GBIC. The <code>summary</code> method details information on the model characteristics, the optimization and penalization procedures as well as the parameter estimates with associated standard errors and confidence intervals. The <em>Type</em> column distinguishes between the <em>fixed</em> parameters set to specific values for identification, the <em>free</em> parameters that have been estimated through ordinary maximum likelihood, and the penalized (<em>pen</em>) parameters. The standard errors here have been computed as the square root of the inverse of the penalized Fisher information matrix (Geminiani et al., 2021). The last columns report 95% confidence intervals (CI) for the model parameters. Standard errors and CI of the penalized parameters shrunken to zero are not displayed. A different significance level can be specified through the <code>level</code> argument in the <code>summary</code> call.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">scad.fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/penfa.html">penfa</a></span><span class="op">(</span><span class="co">## factor model </span>
                  model <span class="op">=</span> <span class="va">syntax</span>, 
                  data <span class="op">=</span> <span class="va">ccdata</span>, 
                  std.lv <span class="op">=</span> <span class="cn">TRUE</span>, 
                  <span class="co">## penalization</span>
                  pen.shrink <span class="op">=</span> <span class="st">"scad"</span>, 
                  <span class="co"># optimal tuning</span>
                  eta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>shrink <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lambda"</span> <span class="op">=</span> <span class="va">optimtun.scad</span><span class="op">)</span>, diff <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"none"</span> <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span>,
                  strategy <span class="op">=</span> <span class="st">"fixed"</span>, 
                  verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">scad.fit</span><span class="op">)</span>
<span class="co">## penfa 0.0.0.9000 reached convergence</span>
<span class="co">## </span>
<span class="co">##   Number of observations                                    767</span>
<span class="co">##   Number of groups                                            1</span>
<span class="co">##   Number of observed variables                               12</span>
<span class="co">##   Number of latent factors                                    2</span>
<span class="co">##                                                                </span>
<span class="co">##   Estimator                                                PMLE</span>
<span class="co">##   Optimization method                              trust-region</span>
<span class="co">##   Information                                            fisher</span>
<span class="co">##   Strategy                                                fixed</span>
<span class="co">##   Number of iterations                                       56</span>
<span class="co">##   Number of parameters:                                        </span>
<span class="co">##     Free                                                     13</span>
<span class="co">##     Penalized                                                22</span>
<span class="co">##   Effective degrees of freedom                           26.424</span>
<span class="co">##   GIC                                                 17224.457</span>
<span class="co">##   GBIC                                                17347.131</span>
<span class="co">##                                                                </span>
<span class="co">##   Penalty function:                                            </span>
<span class="co">##     Sparsity                                               scad</span>
<span class="co">##                                                                </span>
<span class="co">##   Additional tuning parameter                                  </span>
<span class="co">##     scad                                                    3.7</span>
<span class="co">##                                                                </span>
<span class="co">##   Optimal tuning parameter:                                    </span>
<span class="co">##     Sparsity                                                   </span>
<span class="co">##      - Factor loadings                                    0.114</span>
<span class="co">##                                                                </span>
<span class="co">## </span>
<span class="co">## Parameter Estimates:</span>
<span class="co">## </span>
<span class="co">## Latent Variables:</span>
<span class="co">##                     Type    Estimate  Std.Err     2.5%    97.5%</span>
<span class="co">##   help =~                                                      </span>
<span class="co">##     h1               pen       0.779    0.030    0.720    0.839</span>
<span class="co">##     h2               pen       0.875    0.029    0.818    0.931</span>
<span class="co">##     h3               pen       0.788    0.030    0.729    0.847</span>
<span class="co">##     h4               pen       0.915    0.031    0.854    0.976</span>
<span class="co">##     h5               pen       0.831    0.034    0.765    0.897</span>
<span class="co">##     h6               pen       0.812    0.036    0.740    0.883</span>
<span class="co">##     h7               pen       0.507    0.050    0.409    0.604</span>
<span class="co">##     v1             fixed       0.000             0.000    0.000</span>
<span class="co">##     v2               pen       0.000                           </span>
<span class="co">##     v3               pen       0.000                           </span>
<span class="co">##     v4               pen       0.000                           </span>
<span class="co">##     v5               pen      -0.000                           </span>
<span class="co">##   voice =~                                                     </span>
<span class="co">##     h1             fixed       0.000             0.000    0.000</span>
<span class="co">##     h2               pen      -0.002                           </span>
<span class="co">##     h3               pen       0.000                           </span>
<span class="co">##     h4               pen      -0.020                           </span>
<span class="co">##     h5               pen       0.039                           </span>
<span class="co">##     h6               pen       0.082    0.026    0.031    0.132</span>
<span class="co">##     h7               pen       0.370    0.049    0.274    0.465</span>
<span class="co">##     v1               pen       0.862    0.029    0.806    0.918</span>
<span class="co">##     v2               pen       0.881    0.028    0.826    0.937</span>
<span class="co">##     v3               pen       0.852    0.029    0.795    0.909</span>
<span class="co">##     v4               pen       0.853    0.029    0.796    0.910</span>
<span class="co">##     v5               pen       0.814    0.030    0.756    0.872</span>
<span class="co">## </span>
<span class="co">## Covariances:</span>
<span class="co">##                     Type    Estimate  Std.Err     2.5%    97.5%</span>
<span class="co">##   help ~~                                                      </span>
<span class="co">##     voice           free       0.879    0.011    0.858    0.901</span>
<span class="co">## </span>
<span class="co">## Variances:</span>
<span class="co">##                     Type    Estimate  Std.Err     2.5%    97.5%</span>
<span class="co">##    .h1              free       0.384    0.021    0.343    0.426</span>
<span class="co">##    .h2              free       0.231    0.014    0.203    0.258</span>
<span class="co">##    .h3              free       0.371    0.021    0.330    0.411</span>
<span class="co">##    .h4              free       0.186    0.012    0.162    0.210</span>
<span class="co">##    .h5              free       0.235    0.014    0.208    0.263</span>
<span class="co">##    .h6              free       0.201    0.012    0.177    0.225</span>
<span class="co">##    .h7              free       0.265    0.015    0.236    0.294</span>
<span class="co">##    .v1              free       0.244    0.015    0.214    0.273</span>
<span class="co">##    .v2              free       0.208    0.013    0.181    0.234</span>
<span class="co">##    .v3              free       0.261    0.016    0.230    0.292</span>
<span class="co">##    .v4              free       0.260    0.016    0.229    0.291</span>
<span class="co">##    .v5              free       0.326    0.019    0.289    0.363</span>
<span class="co">##     help           fixed       1.000             1.000    1.000</span>
<span class="co">##     voice          fixed       1.000             1.000    1.000</span></code></pre></div>
<p>The penalty matrix can be inspected and plotted as shown in <code><a href="../articles/automatic-tuning-selection.html">vignette("automatic-tuning-selection")</a></code>.</p>
</div>
<div id="implied-moments" class="section level4">
<h4 class="hasAnchor">
<a href="#implied-moments" class="anchor"></a>Implied moments</h4>
<p>The implied moments (here, the covariance matrix) can be found via the <code>fitted</code> method.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">implied</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">scad.fit</span><span class="op">)</span>
<span class="va">implied</span>
<span class="co">## $cov</span>
<span class="co">##    h1    h2    h3    h4    h5    h6    h7    v1    v2    v3    v4    v5   </span>
<span class="co">## h1 0.992                                                                  </span>
<span class="co">## h2 0.680 0.993                                                            </span>
<span class="co">## h3 0.614 0.688 0.991                                                      </span>
<span class="co">## h4 0.699 0.783 0.707 0.992                                                </span>
<span class="co">## h5 0.674 0.755 0.682 0.776 0.984                                          </span>
<span class="co">## h6 0.688 0.771 0.696 0.792 0.765 0.983                                    </span>
<span class="co">## h7 0.648 0.726 0.655 0.745 0.723 0.742 0.988                              </span>
<span class="co">## v1 0.591 0.661 0.597 0.676 0.663 0.686 0.703 0.987                        </span>
<span class="co">## v2 0.604 0.676 0.611 0.692 0.678 0.701 0.719 0.760 0.985                  </span>
<span class="co">## v3 0.584 0.654 0.590 0.669 0.656 0.678 0.695 0.735 0.751 0.987            </span>
<span class="co">## v4 0.584 0.654 0.591 0.669 0.656 0.678 0.695 0.735 0.752 0.727 0.987      </span>
<span class="co">## v5 0.558 0.624 0.564 0.639 0.626 0.647 0.663 0.702 0.717 0.693 0.694 0.989</span></code></pre></div>
</div>
</div>
<div id="factor-scores" class="section level3">
<h3 class="hasAnchor">
<a href="#factor-scores" class="anchor"></a>Factor scores</h3>
<p>Lastly, the factor scores can be calculated via the <code>penfaPredict</code> function.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fscores</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/penfaPredict.html">penfaPredict</a></span><span class="op">(</span><span class="va">scad.fit</span><span class="op">)</span></code></pre></div>
<div id="htmlwidget-61157d633700e565af1c" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-61157d633700e565af1c">{"x":{"filter":"none","extensions":["Buttons","Scroller"],"data":[[-0.436712338109278,-0.0868025479005196,0.568576569465433,0.108953572643586,0.378777579099314,-0.630620388446462,0.896564770223206,0.482509454315717,0.787759390002809,0.568576569465433,-0.0066357879743012,-0.311093021812988,1.19700795122573,-1.00137446717881,-0.510455428477267,0.568576569465433,1.25951051550818,0.178880664966064,0.178880664966064,-0.161401197619751,-1.06791464836797,-2.88094764152061,-0.331890125714805,0.334272007767418,-2.8772617586879,0.313914968221807,1.32673317298074,-0.959607805248447,1.26531944398988,1.32673317298074,-0.203683046809185,0.904837088846533,-0.675623505018041,-0.622484367441016,-1.07796200890082,1.32673317298074,-3.22220644811113,-0.42145371223237,0.266635708715127,0.985280577059549,0.525485450144501,0.588435029237191,0.132167774612157,0.363893208014261,1.1041173051666,1.20390571499901,-2.43959999404394,0.830438884587048,-2.04622276440298,1.12153898932769,-0.905624219477366,0.506937397680171,0.869496848935156,0.519307468097445,0.568576569465433,0.568576569465433,-0.127940862264617,0.106276519029383,0.0078025794155924,1.27324795554248,0.0884603916931146,-0.132704561068763,-2.34705968391223,0.0226906820081479,1.01201089608852,1.12829264106491,0.704813105345371,-0.0690704827816785,0.206091004716406,0.409610567047956,1.32673317298074,1.31638633518817,0.568576569465433,0.694041916036628,0.269409396889911,-3.22220644811113,1.10551362567092,0.223438641038111,1.32673317298074,-0.165130183498003,0.544126718913556,-0.106635103156212,0.544126718913556,-0.189580034049879,-0.947736637565192,-2.38083913732134,1.27123079656204,1.09079852938835,1.04165853863082,-2.39190944541142,1.02040067149845,1.32673317298074,0.568576569465433,-0.214029884601756,-0.189580034049879,0.136750796908274,-0.189580034049879,-0.189580034049879,-0.199926871842451,-0.489058338301974,1.32673317298074,0.8161251352463,-0.584981557742602,0.664808906583445,0.348515755582575,-0.189580034049879,0.0350414226266567,1.30228332242887,-0.397351851863107,-0.181809450764885,1.29569265960303,1.32673317298074,0.421921622249959,0.343779029658506,0.499454881457642,1.0644719518531,-2.0770883534403,1.0135992399091,-0.261797675229352,1.32673317298074,0.568576569465433,0.500168552384701,0.526989815550667,0.209750261367924,0.568576569465433,-0.506190841368412,0.138459021404594,0.568576569465433,0.554473556706127,0.144719942554489,1.15124793195537,0.382016625052608,0.568576569465433,0.568576569465433,1.07850378099306,1.32673317298074,1.09242861128273,0.478089767748032,-2.87733184070903,-0.0166472711362842,0.431727949010093,0.568576569465433,0.431727949010093,0.451943414539288,0.568576569465433,0.494970952526925,0.361878507038319,0.476470160387358,-0.261999944681342,0.568576569465433,0.064205895176346,0.064205895176346,-0.0606658055920436,0.778141694783908,0.978969182771487,-2.46404984459582,1.26823809263895,1.26531944398988,0.133355443776057,-2.64330820783868,0.568576569465433,0.284364782826253,0.894960591792754,0.833406826031996,1.26823809263895,-1.09178617662644,-0.0862706616860108,-0.261999944681342,0.511701096484316,-1.88295809088343,0.521228147393727,1.07307489563954,0.44309278517378,0.619465278194094,0.625323561392642,1.32673317298074,0.914088672071091,1.1538423402736,-0.549349942319089,0.975762690930001,1.32673317298074,0.568576569465433,-0.959670359838574,0.407113740012105,1.31263016022144,0.3631908213189,-0.691588604777796,1.32673317298074,0.975762690930001,0.568576569465433,0.445749111483701,1.13991750998392,0.510081489123642,0.510081489123642,1.2372916009409,1.32673317298074,1.06440076823375,1.32673317298074,0.204065074152248,0.644709233335346,0.441462703279401,-0.125905410012238,1.31263016022144,0.443154703165478,0.323202413561581,1.32673317298074,0.483667237018777,0.267049350294849,0.53732709885862,0.100596701158141,0.561148380321937,1.32673317298074,1.32673317298074,1.32673317298074,1.32673317298074,0.568576569465433,-2.80065305283069,1.25152372431067,0.293662166574966,1.32673317298074,1.31638633518817,1.09855530183808,0.404097510080658,0.926009604481986,1.2883584921392,1.04626889830901,0.172566430655822,1.12230220277274,-0.793583939540227,-2.25186266485994,0.654237636956388,1.32673317298074,1.0097482822089,1.32673317298074,1.32673317298074,1.32673317298074,-3.20709591151441,1.32673317298074,1.32673317298074,-2.23897300450686,0.691429484374095,-1.25975969218617,-0.738079241517088,-2.01994883990151,0.449279843656039,0.790667760857012,0.503713958587926,-0.621685607603545,0.510081489123642,1.1791038136792,-0.564850875500328,0.102957253906513,1.32673317298074,-0.52670359327437,-0.196760735702856,-0.46813938869049,-1.0783251826356,-2.65939354539295,-0.501685587080824,0.213216089453185,0.360104656866545,1.31263016022144,1.21791239557438,0.90650874275342,0.568576569465433,0.517650154896626,-1.36011157566621,0.936130301194202,0.530201888623884,0.454180817100074,-0.175655203760207,0.536462078712766,0.579535490781267,1.04084230253931,0.627071649807223,0.341229781273665,1.32673317298074,0.646405625289064,0.834162694196606,-0.326256693180073,0.403105761872351,0.448667760132776,0.362030357446045,0.393091328440061,-1.05665423142676,0.393091328440061,-2.18044554244394,-2.5010137230348,0.239313540163797,-2.46404984459582,-1.60158926234939,0.643472019313619,0.846773695319267,1.04151621882501,0.633439180342939,0.485058015787983,1.32673317298074,1.32673317298074,1.2988835124014,1.32673317298074,1.31162263638403,1.32673317298074,0.629078737080323,1.32673317298074,1.32673317298074,1.32673317298074,0.496816002681996,1.0561527922071,1.32673317298074,0.850637402865484,1.32673317298074,-0.494196120559433,-1.44735316753475,-1.9454485056624,0.238196576540308,1.32673317298074,-1.30302837489388,-0.678044608427433,0.196764043464052,-1.38998370843077,-1.13088845041468,-0.0342513810964973,1.30228332242887,0.0161965401208801,0.141480013818776,0.255971603476375,0.256031971403279,-1.31284478687843,-0.466839462805639,0.456596271685376,-0.647576956779691,-1.42927964110457,-0.143846826204492,-0.47666424893251,0.228815121651479,0.939064532273018,1.06797876073085,-0.231463131082904,-0.510389081418205,-1.50851062761503,-0.228132897361062,-1.29802310564135,-1.3873723532996,-1.39262305574568,-0.966059247235125,0.0281532083908325,-0.180815262334603,-1.17261159256429,1.32673317298074,0.593026420017309,1.04305181171178,1.32673317298074,1.31280834269107,-3.22220644811113,0.676604791295075,-1.13418172957741,0.756352495974902,0.31867516537692,-0.251219205835142,-0.731950039572219,-1.02412191804512,-1.35288401407733,-0.698294118538135,-0.256932368565629,0.0987550469678153,-0.132255928756541,-0.915493261568919,-0.939985042327242,-0.298922443240473,-0.769343032998565,-1.18228358825622,-0.879220997179953,-1.47934984389986,-1.77912873866014,-1.80299463386548,-0.884899102859113,0.374010027059057,0.663601627192583,0.0869242621116329,0.84955408157796,0.48038093568788,0.951392955779328,1.32673317298074,0.965884898413515,-1.44183055608283,-2.39070029294019,-2.82114194419631,-1.52483305684039,-2.11791958545153,-2.16215705270023,-2.35623659102686,-1.74793910629257,-1.46300027365528,-2.14154964912025,-0.862957299380404,-1.51015605216779,-0.62518549293034,0.968303854647849,-0.426059801912493,1.0793736834917,-0.365983161208909,0.339785064734716,-0.189580034049879,1.01068194397166,0.312874049337569,0.568576569465433,0.501353911992864,-0.31993074720406,-0.779969171510978,-0.189580034049879,0.152177216342827,-0.460090332802401,-0.763516932951387,0.322846803676827,0.845224630526325,-1.7058932410805,0.0851778320791979,1.20337548176145,0.853581404651899,-0.204690570646597,0.568576569465433,-0.659443889731992,-0.424737519251518,0.155482647253917,0.568576569465433,-0.175655203760207,0.568576569465433,0.792534293370876,-1.11274347288779,-1.36265669955364,-1.13114208921825,0.214321268228315,0.492668225997592,1.26985769999963,-0.93738979977262,-0.687486553363108,-0.11174003208869,0.558229731672862,-0.31993074720406,-1.00915036655606,0.451586408781851,0.424829993104162,0.056974873171513,-0.472611580471989,-0.365389515406104,0.568576569465433,0.82338349985371,0.629609007329897,-2.6755076570055,-0.33517166056622,0.102649454673109,1.27783347187699,-2.0770883534403,-0.542274354270113,0.897395031047085,1.10897088231421,1.31162263638403,1.32673317298074,0.494608235092639,0.034908645810398,0.568576569465433,-0.369810189460058,-1.07109432878449,-0.99248722264697,1.14556081327155,-0.760327328765565,0.537158470873605,-0.346748246637048,1.13881766132711,-0.309925474821911,1.14424641070897,-1.04802937717124,-0.341369891868143,0.234764640852288,-0.237742120823742,-0.733665979116829,1.32673317298074,0.197381457105632,-0.902182803334195,0.853904600633458,-0.391072332589788,-0.357298250907079,0.0727339329766554,0.222880761701366,-0.924472146621478,-0.861068837093308,-0.189580034049879,-0.947736637565192,-0.947736637565192,0.507162840474567,-0.911276583184339,-0.847265715489506,-0.600238089347779,-1.01923333299682,-0.556429636433459,1.21233742061539,-1.00932854902569,-0.501316469674263,0.0138968614527222,-0.245625594416178,0.47818326907256,-0.331133726965575,-0.175230857191195,0.401340406064934,-0.360914840729648,-0.456829246412968,0.568576569465433,0.847553319062542,0.454180817100074,-0.189580034049879,-0.94415864506809,0.0130743684601073,-0.189580034049879,-0.204690570646597,-0.189580034049879,0.00132420722181885,-0.665964659524777,-0.427122203155525,-1.05661778289846,-0.947736637565192,-1.07113943654922,-0.225384246231739,1.22671932035393,-0.835021250411032,-1.12488081054567,0.0132066914885085,0.340596340889566,0.568576569465433,-0.214029884601756,0.389896422502165,-0.160827272070915,-0.205919934891485,0.22224677099068,0.601614275417935,-0.486331752040099,0.516277058334212,1.32673317298074,0.661494254698358,0.906591932376688,0.120106283290103,-1.75750549161079,0.568576569465433,0.346996594305146,0.729553702918222,0.475208824939102,-1.42387314674214,0.224616520263173,1.21637248256136,-3.22220644811113,-0.368695841694887,-0.304772404903153,0.64582669098154,-0.234138618311767,-0.600239201374338,-0.875018774100172,-0.164305042065216,0.43885649258496,0.129165030370437,1.12838897324884,0.568576569465433,-0.00788773770599371,-0.00235455698178596,1.29651209978731,-0.956420109321358,-1.21743989675032,0.0447060899276777,-0.0145024816375418,0.752613891674612,-0.368948440188384,0.71068856416983,-1.7058932410805,-0.234733114671516,1.12247450479747,0.806249928778814,1.10000028584595,-0.00788773770599371,-0.413997530290813,-0.476299451900949,0.510081489123642,0.550075777325865,0.876417836650344,0.980893049990711,0.55465173917576,0.715981557900197,0.181615078309922,0.530201888623884,0.0903938897345656,-0.668751152925056,-0.754325412767302,0.200890706919176,1.22232154097367,0.493238010184894,0.568576569465433,-0.152684898294447,-0.173505531315693,-0.433046073932302,-0.419811779892516,0.293345295986637,-0.0061587149905517,0.579991299022319,-0.604550930533911,0.0589718556334079,-0.165376897923969,0.880387238294657,0.182420190724386,1.32673317298074,0.353384883430248,-0.985622004260534,-2.21612684866275,-0.704904038066868,-0.822313221200443,-0.0961905804680735,0.889649488185568,-0.699165265812154,0.107895957622003,-0.608674914355246,0.587976676861242,-0.910065609573986,-1.00355162070658,0.925865289256019,-1.48624683535772,-0.464059713002483,0.370114891415981,-1.47533203390095,1.24754441705381,1.32673317298074,-0.785192642650614,-0.540763545643904,-0.540763545643904,-0.401962703792524,0.39483281325466,1.13640521553204,-1.30001514775337,0.0688139492974116,0.188330651811227,-1.62128376382948,-0.629091936057939,0.0723125891985792,0.332792326709644,0.792534293370876,-0.867344735109889,-1.32102884462435,0.55465173917576,1.10172011458654,0.919961438846348,1.04165853863082,-0.61724826028175,0.320781078531375,-0.131165451282154,-1.32470388707549,-1.34143488113067,-1.06213238993055,-1.37688542420955,-0.753551250313559,-1.13990964516896,-1.82440045535853,-0.550613735067085,-0.441278026594455,-0.149601175215688,-0.195449792034901,-0.947736637565192,-0.947736637565192,-0.947736637565192,-0.965352675244404,-1.06213238993055,-1.20927471235595,-1.80086253680558,-0.704071369203081,-2.33120944365149,-1.23926339289394,-0.962847174161909,-0.947736637565192,0.868007613392764,1.20974301229716,1.02842047397364,-0.999889224416728,0.0501941628871497,0.584196616670199,-0.189580034049879,-0.550139453257473,-0.375082836779136,0.333701393773871,-0.519667243962017,0.757372043358674,-0.760742792098737,0.443432454434855,-0.970599183754787,1.12141671784436,-0.778452295868706,-0.346549054005461,0.310020606335754,-0.981347966301476,-0.0368147202340656,0.151785606834157,-1.53555939414691,-0.895036656120092,-0.562462473351111,0.204084950461777,-1.18083832139069,-1.91120969621689,-0.239829397518229,0.0168820221822958,-1.50466972079143,-0.218427663982018,0.590078124980011,0.199190068869572,-1.20204766248112,-0.51330773006728,0.568576569465433,0.151734021076444,-0.0535781482909206,-0.174489940847633,-3.07055284255605,0.519103795904485,0.829825788896559,0.543692817859926,0.510081489123642,0.984979200384229,-0.947736637565192,-1.11492830735514,1.05460133524422,-0.366938195239468,-0.287203588489896,0.830890536491968,-2.23904329620307,-0.317479313722095,1.07103065285288,-0.340182073796333,1.32673317298074,-0.261566043627713,0.568576569465433,-0.352809244094343,-0.1006387893663,-0.360628866187454,-0.248960980878584,0.568576569465433,0.568576569465433,-0.617356644640067,-0.954826924514173,0.465339277746377,0.736199720293679,0.969641073380249,0.285802533677581,1.24082233311324,1.32673317298074,0.889220541966266,0.331242489489507,-0.107269194340561,0.972337780883961,-0.675616732650004,0.0726804780105656,1.05761777436486,0.736199720293679,-0.150019646901286,0.568576569465433,-0.954528613486677,-1.78864790947115,-0.73939732163135,-0.715924070246562,-0.936711929485358,-1.62629950717791,-1.82814060970227,0.568576569465433,0.333193641469398,1.3060394973956,0.359624358640371,-2.42096368026439],[0.142307657258278,-0.358802097684022,0.697784607390796,0.619232839323637,0.866306787190477,-0.484305489079122,0.992705622050902,0.538212202655104,0.605226350236515,0.697784607390796,0.0355220698473809,-0.0763539308904868,1.32575256266568,-1.02441199124697,0.421731174987455,0.697784607390796,0.901020323604657,-0.144440052091461,-0.144440052091461,-0.0495277206261819,-0.993252783400829,-2.50318790391221,0.0177671558943932,0.664068908675531,-2.4952112927621,0.807712971250986,1.44294019454466,-1.00638771631958,1.43403177562804,1.44294019454466,-0.161108261100102,0.827408222763811,-0.868513068623182,-0.299632853616227,-1.84255723147366,1.44294019454466,-3.02799332837851,-0.966272304757851,0.680279489358386,1.24502286314118,0.836527480384995,1.31984826344336,-1.31777836439238,-0.0249510181035366,1.10673571859614,1.42512335671143,-2.0856509850848,0.737474479292691,-1.83813927716253,0.251335000427773,-0.0409778981544044,0.200794927524924,1.05530317283127,0.323679809445304,0.697784607390796,0.697784607390796,0.449618700102808,0.524556687554732,0.19500293614524,1.01159715006499,0.510913326352774,0.411204349624631,-2.26586842666904,-0.121315595509749,0.827291125848333,0.79355398674167,1.12093253897719,-0.846357182699489,-0.462498503891229,0.785269790650979,1.44294019454466,1.35949071974185,0.697784607390796,0.730278722923372,0.60547509273604,-3.02799332837851,0.58809075386403,1.00492218575174,1.44294019454466,0.149815776376782,0.500597851250949,0.158300433654586,0.500597851250949,-0.0473709797630647,-0.792526566916926,-1.94067169198062,0.995651863977617,0.932570688580834,0.537623481868489,-2.06990543124202,0.808405461190904,1.44294019454466,0.697784607390796,-0.244557735902912,-0.0473709797630647,-0.375776847387684,-0.0473709797630647,-0.0473709797630647,-0.130820454565874,-0.343393514677113,1.44294019454466,0.931450630925784,-1.24485874530702,0.466650878394124,0.645022770829558,-0.0473709797630647,0.667456602429074,1.24575343840481,-0.0100140678216484,-0.58034902160709,1.19259177013623,1.44294019454466,-0.0959234216027801,-0.185907821545857,0.345763344816119,-0.185421863097015,-2.23081070336403,1.21795833686126,-0.004322394532794,1.44294019454466,0.697784607390796,0.14618844097814,0.36251792156229,0.33788941590561,0.697784607390796,-0.715041222963348,0.406100416208304,0.697784607390796,0.584047326053759,1.20459526104637,1.41748622271124,0.0995780119230643,0.697784607390796,0.697784607390796,1.29693203277056,1.44294019454466,1.40922449582939,-0.0317506574668992,-2.53917596341316,-0.00218381999460634,0.0587516367826231,0.697784607390796,0.0587516367826231,0.477029220465536,0.697784607390796,0.567436124832005,-0.0413090392419408,0.418340014642992,-0.168148100099704,0.697784607390796,0.113738221349195,0.113738221349195,0.0348085327923899,0.732060455723141,0.934461726858751,-2.28283774122465,1.43445553726685,1.43403177562804,-0.0497957991697277,-2.35775417968499,0.697784607390796,0.261568852451888,0.981115747117897,0.669860900055215,1.43445553726685,-0.460288646895389,-0.534987971491409,-0.168148100099704,0.239209278003101,-1.73280036938618,0.31614291220996,1.20474038634705,1.07707213488783,0.621798733226397,0.706994338801682,1.44294019454466,0.430921921444807,1.41813291474601,-0.113580794010906,1.39203225087783,1.44294019454466,0.697784607390796,-0.868496189810546,-0.604476003242664,1.32920291320762,-0.472002120863181,-0.450224860429913,1.44294019454466,1.39203225087783,0.697784607390796,0.679967769557571,1.30584045168717,0.689299950112992,0.689299950112992,1.20800203123217,1.44294019454466,1.18319475143352,1.44294019454466,-0.797743398910812,0.585323702338549,0.600418327639274,0.598131726557379,1.32920291320762,0.67932107752281,0.647897415663803,1.44294019454466,-0.645758227421368,0.122149037735531,0.445801511295303,-0.0292971732355092,0.614758894226795,1.44294019454466,1.44294019454466,1.44294019454466,1.44294019454466,0.697784607390796,-2.72670896283991,1.30089690380236,0.316511903340942,1.44294019454466,1.35949071974185,0.945728439143905,0.78419933697741,0.604923922020478,1.13346097534598,-0.354081448844476,-0.638352661339548,1.23811498173555,0.696649328922661,-1.52260388864103,-0.733222520688539,1.44294019454466,0.330498701702088,1.44294019454466,1.44294019454466,1.44294019454466,-2.90612950309752,1.44294019454466,1.44294019454466,-2.14374928174266,0.502284645006682,-1.23689537389511,-0.240814211574312,-1.85640797486847,0.222174315142539,0.726137330841988,0.639190791451305,-1.17471207780288,0.689299950112992,1.18011978346572,-0.899308265541712,0.0845057507017456,1.44294019454466,-0.580488836607514,-0.568315408028932,0.445039264830136,-1.1850042313778,-2.93035536911063,-0.735521997381368,-0.267352782054432,0.387267062312433,1.32920291320762,1.02993696833236,0.745803672801827,0.697784607390796,0.287299923953934,-1.48806759447348,0.635421983203108,0.388305388192114,0.681461984869948,0.0649214832957704,0.64010905440224,0.323016866139765,0.45728906486079,0.706269264668601,-0.206600297518866,1.44294019454466,0.954874451958011,1.14159708012272,-0.223007766729839,0.31428731274006,0.680391531196379,0.545976312007443,0.672330635557383,-1.32863014982848,0.672330635557383,-0.673916113836375,-2.09455940400141,0.204949680941534,-2.28283774122465,-1.10556584905813,0.14155456845216,1.37359082016294,-0.856574196628355,0.756378423330287,0.0243246156971528,1.44294019454466,1.44294019454466,1.21835526842699,1.44294019454466,1.32107636926367,1.44294019454466,0.793943078705442,1.44294019454466,1.44294019454466,1.44294019454466,0.605426713671374,1.09365319767357,1.44294019454466,1.1365774028829,1.44294019454466,-0.826579114797577,-1.33832448755015,-1.66214468093136,0.565937673012336,1.44294019454466,-1.3871046020692,-0.686967129232875,-0.00338328854985893,-1.26070988206114,-1.31860413116072,-0.40064005155006,1.24575343840481,0.399122948985251,-0.425888860138675,0.732412860979147,0.341011097919341,-1.15469576728176,0.0387211328242651,0.257956905633323,-0.0711303728492421,-1.16275461134441,0.184818140943838,-0.14893228513744,0.149989472846996,1.12985822713409,1.21203773968955,0.359998004968549,-0.727382723181618,-1.29530823816248,-0.358295017239948,-1.42521599454174,-1.57309192040569,-1.33163535807899,-0.940177858827737,-0.198780567199734,-0.229593084543024,-1.31458543271045,1.44294019454466,0.894971363530643,0.990379358723994,1.44294019454466,1.33064773148582,-3.02799332837851,0.663998071249958,-1.17387171459199,0.356374451521176,0.0547427583983314,-0.544360659628937,-0.706473811248739,-1.65147050239089,-1.08436309835364,-0.365130158545145,0.377614432122025,0.546227001594855,0.266890480182389,-1.20918785053621,-1.42675448664586,-0.472521403821187,-0.981302506670436,-0.65939593159853,-0.912727981545866,-1.80777220565452,-1.30872039900163,-1.23215829064832,-0.913692586441741,0.471532787460044,0.977652961777409,0.376320776390884,0.844711032115831,0.401366365827835,1.09446354606351,1.44294019454466,0.833261120054223,-1.33708814880678,-1.69127747280511,-2.86222900918086,-1.42170428448802,-1.76203288540253,-1.70404171669268,-1.8779610589563,-1.72668757316458,-1.38495033338684,-1.95270380094642,-1.00995308459398,-1.56345348842668,-0.0170105975554844,1.20114060414843,-1.00204920657213,0.884290190715779,-0.0261664481762968,0.6651393623491,-0.0473709797630647,-0.177945282011494,0.398471948469605,0.697784607390796,0.155864736450796,-0.867485676364082,-0.652351402490587,-0.0473709797630647,0.0320770486623966,-0.352693305983091,-0.649724221788983,0.0371501736301283,0.346529714055107,-1.53768215407079,-0.060108374605038,1.37586172132736,1.08903357592274,-0.169234805044052,0.697784607390796,-0.357033410687544,-0.136474677771663,-0.125216864032609,0.697784607390796,0.0649214832957704,0.697784607390796,0.648050831303252,-0.659366136613592,-2.56599477465254,-1.24031396235578,0.626295952511308,0.3319057578873,0.984364865156962,-0.709077092114116,-0.704147226918094,-0.13811332474734,0.614335132587987,-0.867485676364082,-0.801434985833538,0.680815292835188,0.0249875590026919,0.2636904636616,-0.619921612593895,-0.0726020212005253,0.697784607390796,0.402529220090271,0.529870411725707,-2.72119245028146,-0.758158616990538,0.473426472253651,1.04856668226496,-2.23081070336403,-0.591403418867296,0.789143805079477,1.39973726823967,1.32107636926367,1.44294019454466,-0.341518455366487,-1.30531836142883,0.697784607390796,-0.523125878354772,-0.859605040134221,-1.23997380705443,0.446337358786969,-0.701862397083667,0.444522578086898,-0.408531650334571,0.878448279822681,0.0262203680369135,1.29099024883337,-0.695111908100737,-0.394875429274614,-0.138675318993463,-0.749990260391598,-0.765306808854961,1.44294019454466,0.00465605809755212,-0.868138076476692,0.39343341829675,-0.765996582233582,-1.16873341836831,0.624156106377685,0.230349238151155,-0.605016106249735,-0.47198693671006,-0.0473709797630647,-0.792526566916926,-0.792526566916926,0.688876188474184,-1.26672912874393,-0.888496407454913,-0.494273309192025,-1.16780788304811,-0.84200337431014,1.42661757202381,-0.80287980411174,-0.285687638222412,-0.475604869075065,-0.404766471356904,0.560621743937795,-0.702365188734563,-0.394906436106069,-0.650709095864263,-0.29311915431094,-0.0551233660496868,0.697784607390796,0.797628767056842,0.681461984869948,-0.0473709797630647,-0.7636835786609,-0.610060452458759,-0.0473709797630647,-0.169234805044052,-0.0473709797630647,-0.112592887826836,-0.746117823965779,-1.2952131409754,-0.814128030069421,-0.792526566916926,-0.796431255164942,-0.336133754649671,0.636471295480103,-1.59043874636129,-0.510595143422614,-0.0678675030473006,0.23004440817947,0.697784607390796,-0.244557735902912,-0.098708993976701,0.25527702173797,-0.0983151552282151,0.153962422934969,0.500955964584804,-0.563185573654446,0.276012925133279,1.44294019454466,0.542134245968971,-0.0882698622779731,-0.0824229949902234,-2.19184628648333,0.697784607390796,-0.162457253359545,0.132398112995607,0.454296138495554,-0.812913426560017,0.00450386737491798,0.553021820677293,-3.02799332837851,-1.25723859483201,-0.512986148150362,0.406681416583266,0.0562949092872349,-0.55062644076103,-0.774879517648852,-0.199757213959221,0.578365010318806,0.615648990738973,1.30247765645778,0.697784607390796,0.205096647722109,-0.532314158526328,1.19921254398268,-1.6308148344894,-0.754252996631948,0.398126361981813,-0.846149261142426,0.482887418238786,-0.651231268757823,-0.300155825041896,-1.53768215407079,-0.411622570578328,0.26027171639798,0.0524642857589865,1.05712337368362,0.205096647722109,-0.158040212627839,-1.11229777901624,0.689299950112992,0.548688497201783,0.624742003324269,1.23741995388013,0.585492144331961,0.364746720951826,0.645757569530179,0.388305388192114,-1.34569321884874,-0.471679439719932,-0.283189749902494,-0.337060307939376,0.601112466628127,0.576583725415349,0.697784607390796,-0.606208671279252,0.139443880125936,-0.154859857808483,-0.535006394628539,-0.0779083978648384,0.208236833230673,0.39795886307775,-0.737209405049166,-0.161833128285878,0.0980569931423006,0.630221466623964,-0.63072578523407,1.44294019454466,0.354947802810704,-0.896847947578113,-1.60450540129788,-0.248392983173171,-0.780412331354156,-0.644806279060437,1.09487292839758,-0.62339313123931,0.20791858439721,-0.641778697868981,-0.338111950411693,-0.71974997459021,-1.08473277284994,0.866839050595593,-0.810333791631472,-0.674075977801179,0.347071278568978,-0.208878771022714,1.26755658766123,1.44294019454466,-0.851168761921083,-0.563844391275245,-0.563844391275245,-0.287266160895775,0.61758932829881,1.35185226307259,-1.38454433057409,-0.495963200053286,0.321822113030158,-1.71182262877994,-0.795934160613119,-0.30725158593566,0.11610232054784,0.648050831303252,-1.08015348647875,-2.04166105098527,0.585492144331961,0.484879463102672,0.731908098301556,0.537623481868489,-0.499200303328865,0.0921144112846536,-0.926887328281295,-0.554920207342276,-1.20376629525337,-0.808849189437774,-0.953263506074534,-1.06344768415505,-0.921605087228362,-0.725385101691587,-0.173632006259134,-0.558802204600889,-0.0585052761033804,-0.29845825260653,-0.792526566916926,-0.792526566916926,-0.792526566916926,-0.270121078570654,-0.808849189437774,-0.832439369214772,-2.38934568375264,-0.416109776349073,-2.19210792308644,-0.866377849424502,-0.914390392197913,-0.792526566916926,0.507170699633787,1.42597087998905,1.39966938487802,-0.653936406320421,-0.276110659297345,-0.585822386892133,-0.0473709797630647,-0.264666001712538,-0.406682614753999,0.246179234412823,-1.08400063715028,0.61079392544274,-0.653982005781236,0.615168657448984,-1.11354431597068,1.15674434149816,-0.820042132805052,-0.38540938845036,-0.631522645304421,-1.06348650238693,0.132419688591887,0.645263068218053,-0.889151325684479,-0.672718302013283,-1.11250317377257,-1.15251932517344,-1.01810407055197,-1.82387800711729,-0.251087121314434,-0.925475769058604,-1.82383563453118,-0.279916564754888,0.568908962253854,1.2042908796011,-0.80323751491818,-0.727806484820427,0.697784607390796,-0.0599784917211472,-0.575295009296438,-0.213288489998783,-2.66155381717536,0.348654037749633,0.345313357147682,0.960259885582992,0.689299950112992,1.25627197980619,-0.792526566916926,-0.333636334213349,0.947573744872846,-1.27860565968588,-0.182145671140161,1.36931169353155,-1.83385708665477,-0.257416284320476,1.14362753562347,-0.848331750703197,1.44294019454466,-0.627810134431747,0.697784607390796,-0.637213054660486,-0.0740047383763708,-1.0969244860267,-0.783710367145158,0.697784607390796,0.697784607390796,-0.660679632538465,-0.775357743787531,0.329711572252623,1.09987490039225,0.86354892658845,0.789155560609773,0.75020857681714,1.44294019454466,0.498313326800284,-0.774525785551149,0.534039960464629,1.16727599060883,-0.947949404450061,-0.182642126873368,1.18096598407426,1.09987490039225,0.271679601657769,0.697784607390796,-0.299849577675748,0.324573385638382,-0.563885482535703,-0.634345819911494,-0.243433232980811,-2.26825232519385,-1.38744611299097,0.697784607390796,0.120599648432938,1.27604124493904,-0.180636703262759,-2.16997772474333]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>help<\/th>\n      <th>voice<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"autoFill":true,"dom":"Bfrtip","buttons":["csv","excel","pdf"],"deferRender":true,"scrollY":200,"scroller":true,"columnDefs":[{"targets":0,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 3, 3, \",\", \".\");\n  }"},{"targets":1,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 3, 3, \",\", \".\");\n  }"},{"className":"dt-right","targets":[0,1]}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":["options.columnDefs.0.render","options.columnDefs.1.render"],"jsHooks":[]}</script>
</div>
<div id="mcp" class="section level3">
<h3 class="hasAnchor">
<a href="#mcp" class="anchor"></a>Mcp</h3>
<p>We can fit a penalized factor model with the mcp penalty in a way similar to the scad. By default the shape parameter of the mcp is set to 3. This value can be conveniently modified through the <code>a.mcp</code> argument. See <code><a href="../reference/penfaOptions.html">?penfaOptions</a></code> for additional details on the possible options.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">GBIC.mcp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">eta.grid</span>, <span class="va">penfa.fixedTun</span>, penalty <span class="op">=</span> <span class="st">"mcp"</span><span class="op">)</span>

<span class="va">optimtun.mcp</span> <span class="op">&lt;-</span> <span class="va">eta.grid</span><span class="op">[[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">GBIC.mcp</span><span class="op">)</span><span class="op">]</span><span class="op">]</span>
<span class="va">q</span> <span class="op">&lt;-</span> <span class="fu">plotly</span><span class="fu">::</span><span class="fu"><a href="https://docs.ropensci.org/plotly/reference/plot_ly.html">plot_ly</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">eta.grid</span>, y <span class="op">=</span> <span class="va">GBIC.mcp</span>, type <span class="op">=</span> <span class="st">'scatter'</span>, mode <span class="op">=</span> <span class="st">'lines'</span><span class="op">)</span>
<span class="fu">plotly</span><span class="fu">::</span><span class="fu"><a href="https://docs.ropensci.org/plotly/reference/layout.html">layout</a></span><span class="op">(</span><span class="va">q</span>,  xaxis <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>showline <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,
               title <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>text <span class="op">=</span> <span class="st">"GBIC values across tuning parameters"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div id="htmlwidget-99f98338650ae5a147b1" style="width:576px;height:384px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-99f98338650ae5a147b1">{"x":{"visdat":{"93a539c0e31":["function () ","plotlyVisDat"]},"cur_data":"93a539c0e31","attrs":{"93a539c0e31":{"x":[0,0.003,0.006,0.009,0.012,0.015,0.018,0.021,0.024,0.027,0.03,0.033,0.036,0.039,0.042,0.045,0.048,0.051,0.054,0.057,0.06,0.063,0.066,0.069,0.072,0.075,0.078,0.081,0.084,0.087,0.09,0.093,0.096,0.099,0.102,0.105,0.108,0.111,0.114,0.117,0.12,0.123,0.126,0.129,0.132,0.135,0.138,0.141,0.144,0.147,0.15],"y":[17396.1792565921,17389.6014759371,17381.8985595585,17377.4475003526,17376.3984090847,17366.7360541118,17363.7258104133,17361.2810838858,17358.193314763,17356.6180355128,17355.6061477839,17354.7982325977,17354.2739316285,17353.9220955603,17353.6947504621,17353.5352135507,17353.4181261318,17353.2631209068,17353.1869279438,17352.8850324691,17352.493304288,17352.1550759209,17351.8134442289,17351.2970438153,17350.8362712574,17350.3122521058,17349.8421009111,17349.4869610913,17349.1025940873,17348.8114388425,17348.9485834663,17349.0132706108,17349.1521395547,17349.3008674659,17349.4710740376,17349.6506695093,17349.8386729338,17350.0313704767,17350.2367433414,17350.3022750224,17349.962718912,17350.0643657053,17349.983056132,17349.9798166904,17346.934432036,17346.887432695,17346.8997203142,17346.871952064,17346.8885200426,17347.2625347378,17347.7291482246],"mode":"lines","alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"xaxis":{"domain":[0,1],"automargin":true,"showline":true,"title":[]},"title":{"text":"GBIC values across tuning parameters"},"yaxis":{"domain":[0,1],"automargin":true,"title":[]},"hovermode":"closest","showlegend":false},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[0,0.003,0.006,0.009,0.012,0.015,0.018,0.021,0.024,0.027,0.03,0.033,0.036,0.039,0.042,0.045,0.048,0.051,0.054,0.057,0.06,0.063,0.066,0.069,0.072,0.075,0.078,0.081,0.084,0.087,0.09,0.093,0.096,0.099,0.102,0.105,0.108,0.111,0.114,0.117,0.12,0.123,0.126,0.129,0.132,0.135,0.138,0.141,0.144,0.147,0.15],"y":[17396.1792565921,17389.6014759371,17381.8985595585,17377.4475003526,17376.3984090847,17366.7360541118,17363.7258104133,17361.2810838858,17358.193314763,17356.6180355128,17355.6061477839,17354.7982325977,17354.2739316285,17353.9220955603,17353.6947504621,17353.5352135507,17353.4181261318,17353.2631209068,17353.1869279438,17352.8850324691,17352.493304288,17352.1550759209,17351.8134442289,17351.2970438153,17350.8362712574,17350.3122521058,17349.8421009111,17349.4869610913,17349.1025940873,17348.8114388425,17348.9485834663,17349.0132706108,17349.1521395547,17349.3008674659,17349.4710740376,17349.6506695093,17349.8386729338,17350.0313704767,17350.2367433414,17350.3022750224,17349.962718912,17350.0643657053,17349.983056132,17349.9798166904,17346.934432036,17346.887432695,17346.8997203142,17346.871952064,17346.8885200426,17347.2625347378,17347.7291482246],"mode":"lines","type":"scatter","marker":{"color":"rgba(31,119,180,1)","line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"xaxis":"x","yaxis":"y","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script><p>The tuning value equal to 0.141 generated the model with the lowest GBIC.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mcp.fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/penfa.html">penfa</a></span><span class="op">(</span><span class="co">## factor model </span>
                 model <span class="op">=</span> <span class="va">syntax</span>, 
                 data <span class="op">=</span> <span class="va">ccdata</span>, 
                 std.lv <span class="op">=</span> <span class="cn">TRUE</span>, 
                 <span class="co">## penalization</span>
                 pen.shrink <span class="op">=</span> <span class="st">"mcp"</span>, 
                 <span class="co"># optimal tuning</span>
                 eta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>shrink <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lambda"</span> <span class="op">=</span> <span class="va">optimtun.mcp</span><span class="op">)</span>, diff <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"none"</span> <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span>,
                 strategy <span class="op">=</span> <span class="st">"fixed"</span>, 
                 verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mcp.fit</span><span class="op">)</span>
<span class="co">## penfa 0.0.0.9000 reached convergence</span>
<span class="co">## </span>
<span class="co">##   Number of observations                                    767</span>
<span class="co">##   Number of groups                                            1</span>
<span class="co">##   Number of observed variables                               12</span>
<span class="co">##   Number of latent factors                                    2</span>
<span class="co">##                                                                </span>
<span class="co">##   Estimator                                                PMLE</span>
<span class="co">##   Optimization method                              trust-region</span>
<span class="co">##   Information                                            fisher</span>
<span class="co">##   Strategy                                                fixed</span>
<span class="co">##   Number of iterations                                       40</span>
<span class="co">##   Number of parameters:                                        </span>
<span class="co">##     Free                                                     13</span>
<span class="co">##     Penalized                                                22</span>
<span class="co">##   Effective degrees of freedom                           26.428</span>
<span class="co">##   GIC                                                 17224.179</span>
<span class="co">##   GBIC                                                17346.872</span>
<span class="co">##                                                                </span>
<span class="co">##   Penalty function:                                            </span>
<span class="co">##     Sparsity                                                mcp</span>
<span class="co">##                                                                </span>
<span class="co">##   Additional tuning parameter                                  </span>
<span class="co">##     mcp                                                       3</span>
<span class="co">##                                                                </span>
<span class="co">##   Optimal tuning parameter:                                    </span>
<span class="co">##     Sparsity                                                   </span>
<span class="co">##      - Factor loadings                                    0.141</span>
<span class="co">##                                                                </span>
<span class="co">## </span>
<span class="co">## Parameter Estimates:</span>
<span class="co">## </span>
<span class="co">## Latent Variables:</span>
<span class="co">##                     Type    Estimate  Std.Err     2.5%    97.5%</span>
<span class="co">##   help =~                                                      </span>
<span class="co">##     h1               pen       0.779    0.030    0.720    0.839</span>
<span class="co">##     h2               pen       0.874    0.029    0.818    0.931</span>
<span class="co">##     h3               pen       0.788    0.030    0.729    0.847</span>
<span class="co">##     h4               pen       0.914    0.030    0.854    0.974</span>
<span class="co">##     h5               pen       0.828    0.033    0.762    0.893</span>
<span class="co">##     h6               pen       0.807    0.037    0.735    0.879</span>
<span class="co">##     h7               pen       0.506    0.050    0.408    0.604</span>
<span class="co">##     v1             fixed       0.000             0.000    0.000</span>
<span class="co">##     v2               pen       0.000                           </span>
<span class="co">##     v3               pen       0.000                           </span>
<span class="co">##     v4               pen       0.000                           </span>
<span class="co">##     v5               pen      -0.000                           </span>
<span class="co">##   voice =~                                                     </span>
<span class="co">##     h1             fixed       0.000             0.000    0.000</span>
<span class="co">##     h2               pen      -0.001                           </span>
<span class="co">##     h3               pen       0.000                           </span>
<span class="co">##     h4               pen      -0.018                           </span>
<span class="co">##     h5               pen       0.042                           </span>
<span class="co">##     h6               pen       0.087    0.027    0.035    0.139</span>
<span class="co">##     h7               pen       0.371    0.049    0.275    0.467</span>
<span class="co">##     v1               pen       0.862    0.029    0.806    0.919</span>
<span class="co">##     v2               pen       0.882    0.028    0.826    0.937</span>
<span class="co">##     v3               pen       0.852    0.029    0.795    0.909</span>
<span class="co">##     v4               pen       0.853    0.029    0.796    0.910</span>
<span class="co">##     v5               pen       0.814    0.030    0.756    0.872</span>
<span class="co">## </span>
<span class="co">## Covariances:</span>
<span class="co">##                     Type    Estimate  Std.Err     2.5%    97.5%</span>
<span class="co">##   help ~~                                                      </span>
<span class="co">##     voice           free       0.879    0.011    0.857    0.900</span>
<span class="co">## </span>
<span class="co">## Variances:</span>
<span class="co">##                     Type    Estimate  Std.Err     2.5%    97.5%</span>
<span class="co">##    .h1              free       0.384    0.021    0.343    0.426</span>
<span class="co">##    .h2              free       0.231    0.014    0.203    0.258</span>
<span class="co">##    .h3              free       0.370    0.021    0.330    0.411</span>
<span class="co">##    .h4              free       0.186    0.012    0.162    0.210</span>
<span class="co">##    .h5              free       0.236    0.014    0.208    0.263</span>
<span class="co">##    .h6              free       0.201    0.012    0.177    0.226</span>
<span class="co">##    .h7              free       0.265    0.015    0.236    0.294</span>
<span class="co">##    .v1              free       0.244    0.015    0.214    0.273</span>
<span class="co">##    .v2              free       0.208    0.013    0.181    0.234</span>
<span class="co">##    .v3              free       0.261    0.016    0.230    0.292</span>
<span class="co">##    .v4              free       0.260    0.016    0.229    0.291</span>
<span class="co">##    .v5              free       0.326    0.019    0.289    0.363</span>
<span class="co">##     help           fixed       1.000             1.000    1.000</span>
<span class="co">##     voice          fixed       1.000             1.000    1.000</span></code></pre></div>
</div>
</div>
<div id="conclusion" class="section level2">
<h2 class="hasAnchor">
<a href="#conclusion" class="anchor"></a>Conclusion</h2>
<p>Implementing the above approach in the multiple-group case would imply carrying out grid searches in three dimensions to find the optimal tuning parameter vector. This is clearly not advisable, as it would introduce further complications and possibly new computational problems and instabilities. For this reason, we suggest users to rely on the automatic tuning parameter selection procedure, whose applicability is demonstrated in the package vignettes for single (<code><a href="../articles/automatic-tuning-selection.html">vignette("automatic-tuning-selection")</a></code>) and multiple-group (<code><a href="../articles/multiple-group-analysis.html">vignette("multiple-group-analysis")</a></code>) penalized models.</p>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<ul>
<li><p>Fan, J., &amp; Li, R. 2001. “Variable Selection via Nonconcave Penalized Likelihood and Its Oracle Properties.” Journal of the American Statistical Association 96(456), 1348–60. <a href="https://doi.org/10.1198/016214501753382273">https://doi.org/10.1198/016214501753382273</a></p></li>
<li><p>Fischer, R., Ferreira, M. C., Van Meurs, N. et al. (2019). “Does Organizational Formalization Facilitate Voice and Helping Organizational Citizenship Behaviors? It Depends on (National) Uncertainty Norms.” Journal of International Business Studies, 50(1), 125-134. <a href="https://doi.org/10.1057/s41267-017-0132-6">https://doi.org/10.1057/s41267-017-0132-6</a></p></li>
<li><p>Fischer, R., &amp; Karl, J. A. (2019). “A Primer to (Cross-Cultural) Multi-Group Invariance Testing Possibilities in R.” Frontiers in psychology, 10, 1507. <a href="https://doi.org/10.3389/fpsyg.2019.01507">https://doi.org/10.3389/fpsyg.2019.01507</a></p></li>
<li><p>Geminiani, E. (2020). “A Penalized Likelihood-Based Framework for Single and Multiple-Group Factor Analysis Models.” PhD thesis, University of Bologna. <a href="http://amsdottorato.unibo.it/9355/">http://amsdottorato.unibo.it/9355/</a></p></li>
<li><p>Geminiani, E., Marra, G., &amp; Moustaki, I. (2021). “Single- and Multiple-Group Penalized Factor Analysis: A Trust-Region Algorithm Approach with Integrated Automatic Multiple Tuning Parameter Selection.” Psychometrika, 86(1), 65-95. <a href="https://doi.org/10.1007/s11336-021-09751-8">https://doi.org/10.1007/s11336-021-09751-8</a></p></li>
</ul>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Elena Geminiani, Giampiero Marra, Irini Moustaki.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
